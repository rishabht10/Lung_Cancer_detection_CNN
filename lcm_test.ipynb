{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "875cc606-510c-4964-a1e7-f8e3699e360f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "44bf5058-17d8-4aa9-9d0e-9efa3a76f78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#checking for device\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8c4b13b2-4b3d-48dd-a566-1a54176ce3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforms\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "85d07e8a-2d7c-4f15-aa14-88c21efde6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "\n",
    "#Path for training and testing directory\n",
    "train_path='R:\\cnn_test\\gdriveCNN\\lc_train'\n",
    "test_path='R:\\cnn_test\\gdriveCNN\\lc_test'\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9d49020c-1561-4389-a60c-4a06d337c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Benign', 'Malignant', 'Normal']\n"
     ]
    }
   ],
   "source": [
    "#categories\n",
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e29df4b5-e9cc-4445-ae7c-0253e34bc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        \n",
    "        #Output size after convolution filter\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        \n",
    "        self.relu1=nn.ReLU()\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "       \n",
    "        self.relu2=nn.ReLU()\n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        \n",
    "        self.relu3=nn.ReLU()\n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "    \n",
    "        #Feed forwad function\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        \n",
    "            #Above output will be in matrix form, with shape (256,32,75,75)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8f5e0534-4d8f-476b-b76f-38dee868872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0619a243-30f9-4df9-ba58-c57264ce6db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optmizer and loss function\n",
    "optimizer=Adam(model.parameters(),lr=0.0001,weight_decay=0.005)\n",
    "loss_function=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bfc5d35a-61fe-40c3-9aa4-c9bfe19b5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d7d0ed2d-91dc-45a9-86d7-263aeedd9cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the size of training and testing images\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9e105c74-5356-4122-ac13-bb95326482b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 90\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8000980-1cea-400d-be77-f98092b80ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 2.23067569732666 Train Accuracy: 41.25%  Test Accuracy: 33.33333333333333%\n",
      "Epoch: 1 Train Loss: 1.1690032482147217 Train Accuracy: 65.0%  Test Accuracy: 28.888888888888886%\n",
      "Epoch: 2 Train Loss: 0.7508823871612549 Train Accuracy: 73.33333333333333%  Test Accuracy: 33.33333333333333%\n",
      "Epoch: 3 Train Loss: 0.40847498178482056 Train Accuracy: 85.83333333333333%  Test Accuracy: 35.55555555555556%\n",
      "Epoch: 4 Train Loss: 0.13030444085597992 Train Accuracy: 94.16666666666667%  Test Accuracy: 54.44444444444444%\n",
      "Epoch: 5 Train Loss: 0.1376965194940567 Train Accuracy: 92.91666666666667%  Test Accuracy: 34.44444444444444%\n",
      "Epoch: 6 Train Loss: 0.027869462966918945 Train Accuracy: 100.0%  Test Accuracy: 38.88888888888889%\n",
      "Epoch: 7 Train Loss: 0.04843901842832565 Train Accuracy: 99.58333333333333%  Test Accuracy: 38.88888888888889%\n",
      "Epoch: 8 Train Loss: 0.028773514553904533 Train Accuracy: 99.58333333333333%  Test Accuracy: 38.88888888888889%\n",
      "Epoch: 9 Train Loss: 0.006120683625340462 Train Accuracy: 100.0%  Test Accuracy: 41.11111111111111%\n",
      "Epoch: 10 Train Loss: 0.006523032672703266 Train Accuracy: 100.0%  Test Accuracy: 51.11111111111111%\n",
      "Epoch: 11 Train Loss: 0.009480816312134266 Train Accuracy: 100.0%  Test Accuracy: 52.22222222222223%\n",
      "Epoch: 12 Train Loss: 0.006071531679481268 Train Accuracy: 100.0%  Test Accuracy: 54.44444444444444%\n",
      "Epoch: 13 Train Loss: 0.00403442932292819 Train Accuracy: 100.0%  Test Accuracy: 58.88888888888889%\n",
      "Epoch: 14 Train Loss: 0.002876241458579898 Train Accuracy: 100.0%  Test Accuracy: 57.77777777777777%\n",
      "Epoch: 15 Train Loss: 0.0027657097671180964 Train Accuracy: 100.0%  Test Accuracy: 60.0%\n",
      "Epoch: 16 Train Loss: 0.0021737655624747276 Train Accuracy: 100.0%  Test Accuracy: 64.44444444444444%\n",
      "Epoch: 17 Train Loss: 0.00212733238004148 Train Accuracy: 100.0%  Test Accuracy: 66.66666666666666%\n",
      "Epoch: 18 Train Loss: 0.002007268602028489 Train Accuracy: 100.0%  Test Accuracy: 62.22222222222222%\n",
      "Epoch: 19 Train Loss: 0.0017217864515259862 Train Accuracy: 100.0%  Test Accuracy: 64.44444444444444%\n",
      "Epoch: 20 Train Loss: 0.0018179883481934667 Train Accuracy: 100.0%  Test Accuracy: 61.111111111111114%\n",
      "Epoch: 21 Train Loss: 0.0018473321106284857 Train Accuracy: 100.0%  Test Accuracy: 63.33333333333333%\n",
      "Epoch: 22 Train Loss: 0.0016092783771455288 Train Accuracy: 100.0%  Test Accuracy: 57.77777777777777%\n",
      "Epoch: 23 Train Loss: 0.0016100682551041245 Train Accuracy: 100.0%  Test Accuracy: 61.111111111111114%\n",
      "Epoch: 24 Train Loss: 0.0016043517971411347 Train Accuracy: 100.0%  Test Accuracy: 60.0%\n",
      "Epoch: 25 Train Loss: 0.0015313099138438702 Train Accuracy: 100.0%  Test Accuracy: 61.111111111111114%\n",
      "Epoch: 26 Train Loss: 0.0014438026119023561 Train Accuracy: 100.0%  Test Accuracy: 60.0%\n",
      "Epoch: 27 Train Loss: 0.0014995186356827617 Train Accuracy: 100.0%  Test Accuracy: 57.77777777777777%\n",
      "Epoch: 28 Train Loss: 0.0014374494785442948 Train Accuracy: 100.0%  Test Accuracy: 62.22222222222222%\n",
      "Epoch: 29 Train Loss: 0.0014780588680878282 Train Accuracy: 100.0%  Test Accuracy: 61.111111111111114%\n",
      "Epoch: 30 Train Loss: 0.0014278549933806062 Train Accuracy: 100.0%  Test Accuracy: 64.44444444444444%\n",
      "Epoch: 31 Train Loss: 0.001416796469129622 Train Accuracy: 100.0%  Test Accuracy: 62.22222222222222%\n",
      "Epoch: 32 Train Loss: 0.0013240097323432565 Train Accuracy: 100.0%  Test Accuracy: 63.33333333333333%\n",
      "Epoch: 33 Train Loss: 0.0013513023732230067 Train Accuracy: 100.0%  Test Accuracy: 58.88888888888889%\n",
      "Epoch: 34 Train Loss: 0.00136655627284199 Train Accuracy: 100.0%  Test Accuracy: 65.55555555555556%\n",
      "Epoch: 35 Train Loss: 0.0012423067819327116 Train Accuracy: 100.0%  Test Accuracy: 62.22222222222222%\n",
      "Epoch: 36 Train Loss: 0.0012765938881784678 Train Accuracy: 100.0%  Test Accuracy: 61.111111111111114%\n",
      "Epoch: 37 Train Loss: 0.0011296633165329695 Train Accuracy: 100.0%  Test Accuracy: 60.0%\n",
      "Epoch: 38 Train Loss: 0.0012360637774690986 Train Accuracy: 100.0%  Test Accuracy: 61.111111111111114%\n",
      "Epoch: 39 Train Loss: 0.0011757846223190427 Train Accuracy: 100.0%  Test Accuracy: 61.111111111111114%\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy=0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "            \n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    \n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print(f'Epoch: {epoch} Train Loss: {train_loss} Train Accuracy: {train_accuracy*100}%  Test Accuracy: {test_accuracy*100}%')\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789361c-8ce7-4a64-b76e-8c935e72333b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcm_test",
   "language": "python",
   "name": "lcm_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
